{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  class\n",
       "0           5.1          3.5           1.4          0.2      0\n",
       "1           4.9          3.0           1.4          0.2      0\n",
       "2           4.7          3.2           1.3          0.2      0\n",
       "3           4.6          3.1           1.5          0.2      0\n",
       "4           5.0          3.6           1.4          0.2      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "df_iris = pd.DataFrame(data.data, columns = ['sepal length', 'sepal width', 'petal length', 'petal width'])\n",
    "df_iris['class'] = data.target\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_model = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "iris_model.fit(df_iris.values, df_iris['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_pred = iris_model.predict(df_iris.values)\n",
    "accuracy_score(iris_pred, df_iris['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_iris.drop('class', axis=1).values\n",
    "Y = df_iris['class'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_model = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "iris_model.fit(x_train, y_train)\n",
    "y_pred = iris_model.predict(x_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(x_train, y_train)  \n",
    "accuracy_score(clf.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xma/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 1, 1, 2, 2, 2, 0,\n",
       "       2, 0, 1, 2, 1, 0, 1, 2, 1, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 2, 2,\n",
       "       0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_clf = MLPClassifier(activation='relu', max_iter=500, hidden_layer_sizes=(20, 30))\n",
    "nn_clf.fit(x_train, y_train)\n",
    "nn_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33123157e-08, 1.29785495e-03, 9.98702132e-01],\n",
       "       [9.96769169e-01, 3.23083054e-03, 1.05165163e-12],\n",
       "       [5.14861869e-10, 2.43557422e-04, 9.99756442e-01],\n",
       "       [9.99685461e-01, 3.14539306e-04, 2.34507745e-15],\n",
       "       [9.47625244e-06, 2.29204796e-01, 7.70785727e-01],\n",
       "       [9.53195276e-09, 2.53579608e-03, 9.97464194e-01],\n",
       "       [9.99474611e-01, 5.25388847e-04, 6.97605681e-15],\n",
       "       [9.96754267e-01, 3.24573269e-03, 1.13823306e-12],\n",
       "       [3.83969033e-07, 3.27193465e-02, 9.67280270e-01],\n",
       "       [9.96051949e-01, 3.94805137e-03, 2.66950615e-12],\n",
       "       [9.98836634e-01, 1.16336570e-03, 1.22001084e-13],\n",
       "       [7.26662036e-08, 5.34386205e-03, 9.94656065e-01],\n",
       "       [9.96560847e-01, 3.43915316e-03, 1.60747224e-12],\n",
       "       [9.98648719e-01, 1.35128106e-03, 9.60697140e-14],\n",
       "       [2.15122858e-07, 1.20774322e-02, 9.87922353e-01],\n",
       "       [4.27689384e-04, 9.98771784e-01, 8.00526217e-04],\n",
       "       [7.93487685e-04, 9.98822573e-01, 3.83939328e-04],\n",
       "       [4.13869127e-05, 8.20735132e-01, 1.79223481e-01],\n",
       "       [1.51013542e-09, 6.53431515e-04, 9.99346567e-01],\n",
       "       [1.04728867e-07, 1.00292296e-02, 9.89970666e-01],\n",
       "       [1.52907398e-07, 3.12634389e-02, 9.68736408e-01],\n",
       "       [9.98113433e-01, 1.88656674e-03, 2.56119781e-13],\n",
       "       [9.00273202e-07, 3.18654103e-02, 9.68133689e-01],\n",
       "       [9.95198415e-01, 4.80158462e-03, 3.08205570e-12],\n",
       "       [9.73257254e-04, 9.98436910e-01, 5.89832611e-04],\n",
       "       [1.29646018e-06, 5.27244014e-02, 9.47274302e-01],\n",
       "       [4.15657637e-04, 9.99011669e-01, 5.72673263e-04],\n",
       "       [9.97416307e-01, 2.58369331e-03, 2.68476876e-13],\n",
       "       [1.20967767e-04, 9.88367720e-01, 1.15113120e-02],\n",
       "       [1.42212795e-08, 2.19378332e-03, 9.97806202e-01],\n",
       "       [2.22434162e-03, 9.97549797e-01, 2.25861627e-04],\n",
       "       [5.05638560e-04, 9.97711875e-01, 1.78248660e-03],\n",
       "       [2.28342158e-06, 6.87024407e-02, 9.31295276e-01],\n",
       "       [9.96854120e-01, 3.14588033e-03, 9.20647798e-13],\n",
       "       [9.99479217e-01, 5.20782830e-04, 1.35943394e-14],\n",
       "       [2.60922597e-04, 9.97697296e-01, 2.04178186e-03],\n",
       "       [9.98654935e-01, 1.34506518e-03, 8.87612503e-14],\n",
       "       [4.79785342e-04, 9.93435542e-01, 6.08467269e-03],\n",
       "       [5.99990947e-09, 8.06743886e-04, 9.99193250e-01],\n",
       "       [3.38638417e-08, 1.77150111e-03, 9.98228465e-01],\n",
       "       [9.87760659e-01, 1.22393414e-02, 6.44818989e-11],\n",
       "       [1.72684379e-04, 9.70506977e-01, 2.93203388e-02],\n",
       "       [1.53065637e-08, 2.74059415e-03, 9.97259391e-01],\n",
       "       [2.12454857e-09, 6.97177708e-04, 9.99302820e-01],\n",
       "       [9.98872499e-01, 1.12750056e-03, 6.92366610e-14]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(nn_clf.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xma/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from keras.layers import Dense, Input, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import rmsprop\n",
    "\n",
    "dataset = load_wine()\n",
    "\n",
    "ensemble_num = 10 # number of sub-networks\n",
    "bootstrap_size = 0.8 # 80% size of original (training) dataset\n",
    "training_size = 0.8 # 80% for training, 20% for test\n",
    "\n",
    "num_hidden_neurons = 10 # number of neurons in hidden layer\n",
    "dropout = 0.25 # percentage of weights dropped out before softmax output (this prevents overfitting)\n",
    "\n",
    "epochs = 200 # number of epochs (complete training episodes over the training set) to run\n",
    "batch = 10 # mini batch size for better convergence\n",
    "\n",
    "# get the holdout training and test set\n",
    "temp = []\n",
    "scaler = MinMaxScaler()\n",
    "one_hot = OneHotEncoder() # one hot encode the target classes\n",
    "dataset['data'] = scaler.fit_transform(dataset['data'])\n",
    "dataset['target'] = one_hot.fit_transform(np.reshape(dataset['target'], (-1,1)) ).toarray()\n",
    "for i in range(len(dataset.data)):\n",
    "    temp.append([dataset['data'][i], np.array(dataset['target'][i])])\n",
    "\n",
    "# shuffle the row of data and targets\n",
    "temp = np.array(temp)\n",
    "np.random.shuffle(temp)\n",
    "# holdout training and test stop index\n",
    "stop = int(training_size*len(dataset.data))\n",
    "\n",
    "train_X = np.array([x for x in temp[:stop,0]])\n",
    "train_Y = np.array([x for x in temp[:stop,1]])\n",
    "test_X = np.array([x for x in temp[stop:,0]])\n",
    "test_Y = np.array([x for x in temp[stop:,1]])\n",
    "\n",
    "# now build the ensemble neural network\n",
    "# first, let's build the individual sub-networks, each\n",
    "# as a Keras functional model.\n",
    "sub_net_outputs = []\n",
    "sub_net_inputs = []\n",
    "for i in range(ensemble_num):\n",
    "    # two hidden layers to keep it simple\n",
    "    # specify input shape to the shape of the training set\n",
    "    net_input = Input(shape = (train_X.shape[1],))\n",
    "    sub_net_inputs.append(net_input)\n",
    "    y = Dense(num_hidden_neurons)(net_input)\n",
    "    y = Dense(num_hidden_neurons)(y)\n",
    "    y = Dropout(dropout)(y)\n",
    "    sub_net_outputs.append(y) # sub_nets contains the output tensors\n",
    "\n",
    "# now concatenate the output tensors\n",
    "y = concatenate(sub_net_outputs)\n",
    "\n",
    "# final softmax output layer\n",
    "y = Dense(train_Y[0].shape[0], activation='softmax')(y)\n",
    "\n",
    "# now build the whole funtional model\n",
    "model = Model(inputs=sub_net_inputs, outputs=y)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "print(\"Begin training...\")\n",
    "\n",
    "# train the model\n",
    "# model.fit( [train_X] * ensemble_num, train_Y,validation_data=[ [test_X] * ensemble_num, test_Y],\n",
    "#           epochs=epochs, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
