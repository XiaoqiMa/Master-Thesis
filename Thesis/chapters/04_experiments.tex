After a detailed introduction to methodology , in this chapter, we will concentrate on practical experiments. To begin with, datasets that will be utilized in the experiments will be introduced, including the well-known UCI datasets and the artificial dataset. Next, a general overview of the classification or regression models that might be encountered in the experiments is provided. Then, we intend to compare different local interpretation methods on the same dataset and give explanations on the feature that is interested. To interpret the feature explanation for an individual instance and discover the interesting patterns, subgroup discovery technique is applied. As a comparison, decision tree visualization is exposed to find local patterns. And finally, we will apply the promising SHAP approach to conduct case studies on real datasets. 

\section{Datasets}


\subsection{Artificial dataset}

Before exploring the local interpretation methods on real datasets, we would like to justify the concept that interesting subgroups could be recovered from the artificial dataset by inspecting variable influence. Presumably, there were hidden patterns in the synthetic dataset that were useful to provide reasonable explanation to the predictions. By interpreting the effect of a certain variable, e.g. gender, it was assumed that the interesting pattern could be recovered. The procedure to construct an artificial dataset and conduct experiments will be described as follows. 

For simplicity, we constructed the artificial dataset relying on the popular "Adult Income" dataset, but we only extracted partial information, which meant that only the information about age, education-num, sex, hours-per-week and income were included. As assumed, the synthetic data contained some interesting patterns, such as "age < 30". One exemplary case was that when "age < 30", the attribute "gender" had stronger effect on predictions while in its complementary subgroup, the effect of "gender" was slight. And the task was indeed to discover this pattern by exploring the effect of gender. 

For further experiments, one way to fabricate this interesting pattern was to modify the gender effect directly on the corresponding subgroups. For instance, if the condition that "age < 30" was met, we could manually add 3 unit in terms of the scale of measurement on gender effect, and otherwise we could subtract 3 unit. Another idea was to establish two models that behaved differently when considering this condition. It is known that the coefficients in the logistic regression model have straightforward interpretation, indicating the influence level by the input features. Therefore, we could create two distinct models by changing the weights of the features in accordance with the previous defined patterns, which was that when "age < 30", the effect of gender was relative large. In specific, we could assign larger weights to the model that was applied on the pre-described subgroup to maintain larger gender effect, while decreasing feature weights on the model that was applied on its complementary subgroup.

In this paper, we would like to adopt the latter method to make up the synthetic dataset and build the models. 

\subsection{UCI datasets}

Apart from the synthetic dataset, we will mostly consider datasets that could be found in UCI Machine Learning Repository \cite{asuncion2007uci}. Ideally, we would like to choose datasets that covers various domains, including social, financial and life science areas. Therefore, for classification tasks, concerning the popularity and quality of datasets, we decided to adopt the "Adult Income", "German Credit", and "Breast Cancer Wisconsin" datasets. In Adult Income dataset, there are 14 descriptive features and more than 40 thousand instances, which were extracted from US census database. And the task was to predict whether a person earned more than 50K a year or not. As for the German Credit dataset, it was determined to figure out whether a person had good or bad credit risks relying on the 20 descriptive attributes for each person. It is worth mentioning that these two datasets contain multivariate data types, consisting of categorical features and numerical features. In that regard, data preprocessing needs to be considered in addition. Another Breast Cancer dataset is composed of 32 features and all of them are numerical features except for the predicted label which tells whether the diagnosis of cancer is malignant or benign. Those features of an individual instance are extracted from an image of a breast mass, which describes the characteristics of the cell nuclei in the image. 

For regression tasks, we specifically choose the "Bike Sharing" and "Boston Housing" datasets. In Bike sharing dataset, the task is to predict the count of total rental bikes within a specific time frame. It is made up with 17389 entries and each with 16 distinct features. Regarding the Boston housing dataset, it is derived from US census service concerning housing price in the area of Boston MA. 505 records can be found in the dataset and each record contains 14 numerical features. 

In summary, a general overview of real-world datasets that will be used in experiments is concluded in Table \ref{datasets}

\begin{table}[H] \label{datasets}
	\centering 
	\caption{Datasets used in experiments}
	\ra{1.3}
	\begin{tabular}{{m}{3cm}cccc}\toprule[0.5mm]
		Datasets & Usage & \#Instances & \#Features \\ 
		\midrule[0.3mm]
		Adult Income & Classification & 48842 & 14 \\
		German Credit & Classification & 1000 & 20 \\
		Breast Cancer & Classification & 569 & 32 \\
		Bike Sharing & Regression & 17389 & 16 \\
		Boston Housing & regression & 505 & 14 \\
		\bottomrule[0.5mm]
	\end{tabular}
	
\end{table}


%\subsection{Datasets description}
%
%\subsubsection{Artificial dataset}
%
%\subsubsection{UCI datasets}



%\subsection{Data preprocessing }


\section{Experiments setup}


\subsection{Machine learning models}

The first machine learning algorithm that will be used in experiments is Random Forest, which is an ensemble method for classification or regression tasks by creating multiple decision trees at training time. 

Another black box model is gradient boosting trees, which constructs an ensemble of decision trees to perform classification or regression tasks, where each decision tree is a weak prediction model. 
The gradient boosting trees algorithm requires definition of loss function that can be minimized. The algorithm is called boosting because it builds decision trees iteratively. It creates the first tree and finds the data points with high prediction errors, this errors show which data points should be emphasized by the next decision tree. After building all the decision trees, their predictions of these trees are combined by weighted average, where weight depends on a performance of a tree. Different approaches of building gradient boosting trees depend on many hyperparameters and is an active area of research [112]

%The library that is used for gradient boosting trees in this thesis is called XGBoost [111]. The gradient boosting trees algorithm implemented in XGBoost were a part of winning solutions of multiple machine learning competitions [113], including competitions in natural language processing field. The library also works natively with scipy sparse data format and can convert it to an internal data format, called DMatrix, which speeds up the training process. The main parameters of the algo- rithm are max_depth, num_boost_round and learning_rate. The maximal number of splits that allowed in a tree is defined by max_depth, and the number of trees in an ensemble is determined by num_boost_round. The learning_rate parameter enables regularization of the model, by forcing the algorithm to build more trees to achieve the same score. The XGBoost library also allows the usage of validation set, to stop training if the score on validation data did not improve for a given amount of boosting rounds.

deep neural network

%Another machine learning algorithm that will be used with produced feature vectors is gradient boosting trees [110]. The algorithm creates an ensemble of decision trees that perform classification or regression, where each tree is a weak prediction model. A decision tree is a tree-like graph, where each node represents the split based on one of the features in a feature vector. Figure 12 shows an example with two trees, the nodes represent the ‘decisions’ that split the data into subgroups. In case of ensemble models, the trees are called weak because they are intentionally limited by depth [110].
%The gradient boosting trees algorithm requires definition of loss function that can be minimized. The algorithm is called boosting because it builds decision trees iteratively. It creates the first tree and finds the data points with high prediction errors, this errors show which data points should be emphasized by the next decision tree. After building all the decision trees, their predictions of these trees are combined by weighted average, where weight depends on a performance of a tree. Different approaches of building gradient boosting trees depend on many hyperparameters and is an active area of research [112]. More detailed description of this approach is beyond the scope of this thesis.
%The library that is used for gradient boosting trees in this thesis is called XGBoost [111]. The gradient boosting trees algorithm implemented in XGBoost were a part of winning solutions of multiple machine learning competitions [113], including competitions in natural language processing field. The library also works natively with scipy sparse data format and can convert it to an internal data format, called DMatrix, which speeds up the training process. The main parameters of the algo- rithm are max_depth, num_boost_round and learning_rate. The maximal number of splits that allowed in a tree is defined by max_depth, and the number of trees in an ensemble is determined by num_boost_round. The learning_rate parameter enables regularization of the model, by forcing the algorithm to build more trees to achieve the same score. The XGBoost library also allows the usage of validation set, to stop training if the score on validation data did not improve for a given amount of boosting rounds.
%The gradient boosting trees algorithm is a non-linear algorithm, which means that it can approximate more complex data, but without proper regularization can easily overfit. The non-linear nature of the algorithm means signifies that there is no linear dependency between features (i.e., words) and the target class. But because during the construction of decision trees only the most significant features are used, it is possible to sort features by their importance to a given task. Therefore, in our task, we will be able to use this functionality to extract words that had the most influence in predicting the gender based on the text of the comment.

\subsection{Recover patterns on artificial dataset} 

%Before exploring the local interpretation methods, we would like to justify the concept that interesting subgroups could be recovered from the artificial dataset by inspecting variable influence. Presumably, there were hidden patterns in the synthetic dataset that were useful to provide reasonable explanation to the predictions. By interpreting the effect of a certain variable, e.g. gender, it was assumed that the interesting pattern could be recovered. The procedure to construct an artificial dataset and conduct experiments will be described as follows. 
%
%For simplicity, we constructed the artificial dataset relying on the popular adult dataset, but we only extracted partial information, which meant that only the information about age, education-num, sex, hours-per-week and income were included. As assumed, the synthetic data contained some interesting patterns, such as "age < 30". One exemplary case was that when "age < 30", the attribute "gender" had stronger effect on predictions while in its complementary subgroup, the effect of "gender" was slight. And the task was indeed to discover this pattern by exploring the effect of gender. For further experiments, one way to fabricate the interesting pattern was to modify the gender effect directly on the corresponding subgroups. For instance, if the condition that "age < 30" was met, we could manually add 3 unit in terms of the scale of measurement on gender effect, and otherwise we could subtract 3 unit. Another idea was to establish two models that behaved differently when considering this condition. It is known that the coefficients in the logistic regression model have straightforward interpretation, indicating the influence level by the input features. Therefore, we could create two distinct models by changing the weights of the features in accordance with the previous defined patterns. In specific, we could assign larger weights to the model that was applied on the pre-described subgroup to maintain larger gender effect, while decreasing feature weights on the model that was applied on its complementary subgroup.

As clarified earlier, the artificial dataset was constructed based on Adult dataset with a hidden pattern indicating that the gender had large impact on the prediction when "age < 30". Therefore, the aim was trying to verify whether this interesting subgroup could be recovered by pattern mining technique. 

Firstly, to measure the gender effect, we could simply use the binary flip approach described in previous chapter. By flipping the gender value, i.e. transform from "male" to "female" or the other way around, the prediction change denoted as probability was calculated and roughly it was regarded as the effect of gender. Then, treating the effect of gender as the target concept, subgroup discovery technique was applied on the artificial dataset to discover interesting subgroups. It could be observed that these interesting subgroups include the subgroup that were artificially generated in the dataset. The detailed results were left to the next chapter. In conclusion, it could be proved that subgroup discovery technique could indeed provide us patterns of explanations that facilitate us to understand the predictions. 





\subsection{Comparison of different local interpretation methods}

datasets: adult, credit-g, housing
binary flip: perturbation, LIME, SHAP

numeric perturbation: perturbation, LIME, SHAP

classification vs. regression

decision tree vs. subgroup discovery

\subsection{Case Study}

real world case study 2-3 datasets